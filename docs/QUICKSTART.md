# ğŸš€ Quick Start Guide

Fast reference for getting up and running with the Attack Path Engine.

---

## ğŸ¯ Which Mode Should I Use?

### ğŸ”µ Local Development Mode (venv)

**Choose this if you are:**

- ğŸ‘¨â€ğŸ’» Actively developing features
- ğŸ› Debugging code
- ğŸ§ª Testing changes quickly
- ğŸ“ Writing new functionality

### ğŸŸ¢ Docker Mode

**Choose this if you are:**

- ğŸš€ Deploying to a server
- ğŸ‘¥ Sharing with teammates
- â˜ï¸ Running in production
- ğŸ”„ Setting up CI/CD

---

## ğŸ”µ Local Development Setup (Recommended for Development)

### Step 1: Create Virtual Environment

```bash
python3 -m venv .venv
```

### Step 2: Activate Virtual Environment

```bash
# Linux/Mac
source .venv/bin/activate

# Windows
.venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Configure Environment

```bash
cp .env.example .env
nano .env  # or use your favorite editor
```

Add your API key:

```bash
OPENAI_API_KEY=sk-your-key-here
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7
```

### Step 5: Run the Server

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

âœ… **Server running at**: `http://localhost:8000`  
âœ… **Docs available at**: `http://localhost:8000/docs`  
âœ… **Hot reload enabled** - changes reflect immediately!

---

## ğŸŸ¢ Docker Setup (For Deployment)

### Step 1: Configure Environment

```bash
cp .env.example .env
nano .env  # Add your API key
```

### Step 2: Start with Docker Compose

```bash
docker-compose up -d
```

### Step 3: Check Logs (Optional)

```bash
docker-compose logs -f
```

### Step 4: Stop When Done

```bash
docker-compose down
```

âœ… **Server running at**: `http://localhost:8000`  
âœ… **Containerized** - works the same everywhere!

---

## ğŸ“Š Quick Comparison Table

| Feature | ğŸ”µ Local (venv) | ğŸŸ¢ Docker |
|---------|----------------|-----------|
| **Startup Time** | âš¡ 2-3 seconds | ğŸŒ 10-20 seconds |
| **Code Changes** | Instant (--reload) | Need rebuild |
| **Setup Required** | Python + pip | Just Docker |
| **Debugging** | â­â­â­â­â­ Easy | â­â­ Harder |
| **Portability** | â­â­ OS-dependent | â­â­â­â­â­ Universal |
| **Production Ready** | â­â­ No | â­â­â­â­â­ Yes |
| **Use When** | **Developing NOW** | **Deploying LATER** |

---

## ğŸ§ª Test the API

```bash
# Health check
curl http://localhost:8000/health

# Analyze a host
curl -X POST http://localhost:8000/attack-path \
  -H "Content-Type: application/json" \
  -d '{
    "hostname": "example.com",
    "open_ports": [22, 80, 443],
    "vulnerabilities": ["CVE-2023-12345: SQL Injection"]
  }'

# Or use the example file
curl -X POST http://localhost:8000/attack-path \
  -H "Content-Type: application/json" \
  -d @example_request.json
```

## Run Test Script

```bash
python3 test_engine.py
```

## LLM Provider Configuration

Edit `.env` file:

### OpenAI (Default)

```bash
OPENAI_API_KEY=sk-...
LLM_MODEL=gpt-4o-mini
```

### Anthropic Claude

```bash
ANTHROPIC_API_KEY=sk-ant-...
LLM_MODEL=claude-3-5-sonnet-20241022
```

### Google Gemini

```bash
GEMINI_API_KEY=...
LLM_MODEL=gemini/gemini-pro
```

### Azure OpenAI

```bash
AZURE_API_KEY=...
AZURE_API_BASE=https://your-resource.openai.azure.com
AZURE_API_VERSION=2024-02-15-preview
LLM_MODEL=azure/gpt-4
```

### Local Ollama

```bash
LLM_MODEL=ollama/llama2
# No API key needed, requires Ollama running locally
```

---

## ğŸ”„ Switching Between Modes

### Currently in Local Development? âœ…

```bash
# Just keep working!
# Your changes apply instantly with --reload
```

### Need to Deploy?

```bash
# Commit your changes
git add .
git commit -m "Ready for deployment"

# Switch to Docker
docker-compose up -d

# That's it! Now it's production-ready
```

### Going Back to Development?

```bash
# Stop Docker
docker-compose down

# Activate venv
source .venv/bin/activate

# Resume development
uvicorn app.main:app --reload
```

---

## ğŸ“š API Documentation

Once running, visit:

- Swagger UI: [Swagger UI](http://localhost:8000/docs)
- ReDoc: [ReDoc](http://localhost:8000/redoc)

## Common Models

| Provider | Model | Cost | Quality |
|----------|-------|------|---------|
| OpenAI | gpt-4o-mini | $ | Good |
| OpenAI | gpt-4o | $$$ | Best |
| Anthropic | claude-3-5-sonnet | $$$ | Best |
| Google | gemini-pro | $$ | Good |
| Ollama | llama2 | Free | Good |

## Troubleshooting

### Import Error

```bash
pip install litellm>=1.40.0
```

### API Key Error

Check `.env` file has correct key for your provider

### Slow Responses

- Use faster models (gpt-4o-mini vs gpt-4o)
- Lower temperature in .env
- Check your internet connection

## File Structure

```bash
ai-engine/
â”œâ”€â”€ app/main.py              # Main application
â”œâ”€â”€ .env                     # Configuration
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ test_engine.py          # Test script
â”œâ”€â”€ example_request.json    # Sample data
â”œâ”€â”€ Dockerfile              # Container
â”œâ”€â”€ docker-compose.yml      # Deployment
â””â”€â”€ docs/
    â”œâ”€â”€ README.md           # Quick start
    â”œâ”€â”€ USAGE.md            # Full guide
    â””â”€â”€ IMPLEMENTATION_SUMMARY.md
```

---

## ğŸ’¡ Pro Tips

### For Development (Local)

```bash
# Always activate venv first
source .venv/bin/activate

# Use --reload for instant changes
uvicorn app.main:app --reload

# Keep a terminal open for logs
```

### For Production (Docker)

```bash
# Run in detached mode
docker-compose up -d

# Check logs when needed
docker-compose logs -f

# Update and restart
git pull && docker-compose up -d --build
```

---

## ğŸ“š Next Steps

1. âœ… Choose your mode (Local vs Docker)
2. âœ… Start the server
3. âœ… Test with `curl` or `test_engine.py`
4. ğŸ“– Read [Usage Guide](USAGE.md) for advanced features
5. ï¿½ Check [Deployment Guide](DEPLOYMENT_GUIDE.md) for deployment options
6. ğŸ” See [Implementation Summary](IMPLEMENTATION_SUMMARY.md) for technical details

---

## ğŸ†˜ Support

- ğŸ“– Full Documentation: See [USAGE.md](USAGE.md)
- ğŸš€ Deployment Guide: See [DEPLOYMENT_GUIDE.md](DEPLOYMENT_GUIDE.md)
- âœ… Implementation Details: See [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)
- ğŸ  Back to main [README](../README.md)

---

**Remember:**

- ğŸ”µ **Local = Development** (Use daily)
- ğŸŸ¢ **Docker = Deployment** (Use when ready)
