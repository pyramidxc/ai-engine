# LLM Configuration
# Choose your LLM provider and add the corresponding API key below

# ============================================
# OpenAI Configuration (Default)
# ============================================
OPENAI_API_KEY=your-openai-api-key-here
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7

# ============================================
# Alternative Providers
# ============================================

# Anthropic Claude
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# LLM_MODEL=claude-3-5-sonnet-20241022

# Google Gemini
# GEMINI_API_KEY=your-gemini-api-key-here
# LLM_MODEL=gemini/gemini-pro

# Azure OpenAI
# AZURE_API_KEY=your-azure-api-key-here
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2024-02-15-preview
# LLM_MODEL=azure/gpt-4

# Ollama (Local - No API Key Needed)
# LLM_MODEL=ollama/llama2

# ============================================
# Optional Settings
# ============================================

# Temperature: Controls randomness (0.0 = deterministic, 2.0 = very creative)
# LLM_TEMPERATURE=0.7

# ============================================
# Notes
# ============================================
# - Uncomment the provider you want to use
# - Keep API keys secret - never commit this file!
# - Use .env.example as a template
